{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 7 - Web Scraping \n",
    "\n",
    "## Nossa agenda\n",
    "\n",
    "1.  Definição\n",
    "1.  HTML e Scraping com o pacote BeautifulSoup\n",
    "1.  HTTP, APIs e o pacote Requests\n",
    "1.  Escrita de arquivos e CSV\n",
    "\n",
    "## Me manda uma mensagem\n",
    "\n",
    "#wilsontayar no [slack](https://terahq.slack.com)\n",
    "\n",
    "/wilsontayar no [github](https://github.com/wilsontayar)\n",
    "\n",
    "@wilsontayar no [twitter](https://twitter.com/wilsontayar)\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que é Web Scraping\n",
    "\n",
    "Web Scraping, ou **Web Data Extraction**, é uma técnica onde dados são **extraídos de fontes da web e salvas em seu computador** ou em um banco de dados.\n",
    "\n",
    "Nesta aula vamos ver como podemos extrair dados de páginas da web e de APIs.\n",
    "\n",
    "Também veremos como podemos armazená-las e consumi-las em uma planilha.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que é HTML\n",
    "\n",
    "**Hypertext Markup Language**, ou HTML, é uma **forma padrão** para se escrever páginas da web.\n",
    "\n",
    "Ao contrário do que muitas pessoas falam, **HTML não é uma linguagem de programação**, e sim **uma linguagem de marcação**.\n",
    "\n",
    "Exemplo de HTML:\n",
    "\n",
    "```html\n",
    "<body>\n",
    "    <div id=\"first-person\" class=\"person\">\n",
    "        <span class=\"name\">Fulano</span>\n",
    "        <p class=\"bio\">É um exemplo de pessoa</p>\n",
    "    </div>\n",
    "</body>\n",
    "```\n",
    "\n",
    "Sempre que você abre uma página na internet, **seu navegador irá fazer o download do HTML da página e interpretá-lo**.\n",
    "\n",
    "É a partir dessa interpretação que cores, espaçamentos, fontes e bordas irão aparecer.\n",
    "\n",
    "\n",
    "O **HTML é composto por tags**. Cada **tag tem um propósito** diferente.\n",
    "\n",
    "Por exemplo, o propósito da tag `body` é iniciar o corpo do HTML, onde todas as outras tags irão existir.\n",
    "\n",
    "---\n",
    "\n",
    "As tags podem conter **atributos**. **Atributos ajudam as tags a representar o sentido delas** e o que o navegador deverá fazer ao interpretar aquela tag.\n",
    "\n",
    "Para o web scraping, **o mais importante é perceber o padrão das tags**.\n",
    "\n",
    "Por exemplo, imagine que nós queremos extrair a lista de produtos de um site de vendas.\n",
    "\n",
    "![página de smartphones de uma loja virtual - kabum](images/loja_virtual.PNG)\n",
    "\n",
    "Agora vamos ver o HTML dessa página\n",
    "\n",
    "![html de uma loja virtual - kabum](images/loja_virtual_html_1.PNG)\n",
    "\n",
    "Perceba que cada produto está dentro da `<div class=\"listagem-box\">`\n",
    "\n",
    "Ao abrirmos esta `div`, percebemos outros padrões no HTML, como grifados na foto abaixo:\n",
    "\n",
    "![html de uma loja virtual - kabum](images/loja_virtual_html_2.PNG)\n",
    "\n",
    "*Fonte das fotos: https://www.kabum.com.br/celular-telefone/smartphones*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Como Funciona o BeautifulSoup\n",
    "\n",
    "O pacote BeautifulSoup (bs4) foi construido para **realizar web scraping de forma fácil**. Ele transforma o HTML de uma página em um objeto python.\n",
    "\n",
    "Existem 4 tipos de informação no bs4:\n",
    "- Tag\n",
    "- NavigableString\n",
    "- BeautifulSoup\n",
    "- Comment\n",
    "\n",
    "A mais importante para o scraping é a Tag. É nela que estão os dados da página.\n",
    "O objeto da Tag pode ser acessado da seguinte forma: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "div\n",
      "<span class=\"produto\">Meu produto</span>\n",
      "['produto']\n",
      "<span class=\"produto\" id=\"meu-unico-produto\">Meu produto</span>\n",
      "{'class': ['produto'], 'id': 'meu-unico-produto'}\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup('<div class=\"produto\">Meu produto</div>', 'html.parser')\n",
    "tag = soup.div\n",
    "\n",
    "# Nossa div\n",
    "print(tag.name)\n",
    "\n",
    "# Trocando div por um span\n",
    "tag.name = \"span\"\n",
    "print(tag)\n",
    "\n",
    "# Acessando dados de atributos\n",
    "print(tag['class'])\n",
    "\n",
    "# Adicionando atributos\n",
    "tag['id'] = \"meu-unico-produto\"\n",
    "\n",
    "print(tag)\n",
    "\n",
    "# Todos os atributos\n",
    "print(tag.attrs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Para baixarmos um HTML da web, vamos precisar da ajuda de outro pacote.\n",
    "\n",
    "Vamos estudar o **pacote Requests** um pouco mais a frente, mas por enquanto, só precisamos saber que ele consegue fazer o download de uma página HTML para depois passarmos para o bs4.\n",
    "\n",
    "No exemplo abaixo estamos indo até a página de uma loja virtual, baixando seu HTML, passando pelo bs4 e realizando o scraping da descriçao de um produto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smartphone Samsung Galaxy J5 Prime SM-G570M, Quad Core 1.4Ghz, Android 6.0.1,Tela 5, 32GB, 13MP, Leitor Digital, Dual Chip, Desbl - Dourado..\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page = requests.get('https://www.kabum.com.br/celular-telefone/smartphones').text\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "print(soup.find('span', {'class': 'H-subtitulo'}).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Podemos fazer isso para todos os produtos, como no exemplo abaixo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smartphone Samsung Galaxy J5 Prime SM-G570M, Quad Core 1.4Ghz, Android 6.0.1,Tela 5, 32GB, 13MP, Leitor Digital, Dual Chip, Desbl - Dourado\n",
      "R$ 646,90\n",
      "-------------\n",
      "Smartphone Asus Zenfone Go ZB500KG-1A002BR, Quad Core, Android 5.1, Tela 5´, 8GB, 8MP, 3G, Dual Chip Desbloqueado - Preto\n",
      "R$ 339,15\n",
      "-------------\n",
      "Smartphone Samsung Galaxy J5 Prime SM-G570M, Quad Core 1.4Ghz, Android 6.0.1,Tela 5, 32GB, 13MP, Leitor Digital, Dual Chip, Desbl - Preto\n",
      "R$ 649,89\n",
      "-------------\n",
      "Smartphone Asus Zenfone Go ZB500KG-3G027BR, Quad Core, Android 5.1, Tela 5´, 8GB, 8MP, 3G, Dual Chip Desbloqueado - Dourado\n",
      "R$ 339,15\n",
      "-------------\n",
      "Smartphone Asus Zenfone Go ZB500KG-3H028BR, Quad Core, Android 5.1, Tela 5´, 8GB, 8MP, 3G, Dual Chip Desbloqueado - Prata\n",
      "R$ 339,15\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page = requests.get('https://www.kabum.com.br/celular-telefone/smartphones').text\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "produtos = soup.find_all('div', {'class': 'listagem-box'})\n",
    "\n",
    "for produto in produtos[0:5]:\n",
    "    print(produto.find('span', {'class': 'H-titulo'}).a.text)\n",
    "    print(produto.find('div', {'class': 'listagem-preco'}).text)\n",
    "    print('-------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 1 - Extraindo Dados do CoinMarketCap\n",
    "\n",
    "Vamos usar requests e BeautifulSoup para o scraping do site https://coinmarketcap.com.\n",
    "\n",
    "Deveremos extrair os seguintes dados:\n",
    "- Nome da moeda\n",
    "- Preço atual\n",
    "- O valor de mercado total\n",
    "- O valor atual em circulação\n",
    "- Percentual de mudança nas últimas 24 horas\n",
    "\n",
    "Tempo: 15 minutos\n",
    "\n",
    "Dica: acesse a página pelo seu navegador e veja o código fonte dela\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moed: $222 (1.56% / 24h)\n",
      "Em circulação: 46465\n",
      "Valor de mercado: $555\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page = requests.get('https://coinmarketcap.com').text\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "moedas = [1]\n",
    "\n",
    "for moeda in moedas[0:5]:\n",
    "    nome = 'moed'\n",
    "    preco = '$222'\n",
    "    valor_mercado = '$555' \n",
    "    em_circulacao = '46465'\n",
    "    percentual_dia = '1.56%'\n",
    "    print('{0}: {1} ({2} / 24h)'.format(nome, preco, percentual_dia))\n",
    "    print('Em circulação: {0}'.format(em_circulacao))\n",
    "    print('Valor de mercado: {0}'.format(valor_mercado))\n",
    "    print('-------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algumas Considerações\n",
    "\n",
    "A prática de web scraping as vezes é bloqueada por alguns sites (amazon, por exemplo). Nesses casos, opte por APIs.\n",
    "\n",
    "Lembre-se de realizar scraping para tarefas lícitas. Muitos conteúdos na internet possuem copyright e não permitem a publicação do material em outro lugar.\n",
    "\n",
    "Alguns casos na mídia:\n",
    "\n",
    "[The Verge - Microsoft ordered to let third parties scrape LinkedIn data](https://www.theverge.com/2017/8/15/16148250/microsoft-linkedin-third-party-data-access-judge-ruling)\n",
    "\n",
    "[The Atlantic - Aaron's Law: Violating a Site's Terms of Service Should Not Land You in Jail](https://www.theatlantic.com/technology/archive/2013/01/aarons-law-violating-a-sites-terms-of-service-should-not-land-you-in-jail/267247/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como funciona o protocolo HTTP\n",
    "\n",
    "A internet trafega através do protocolo HTTP, ou **Hypertext Transfer Protocol**. O protocolo HTTP foi criado por Tim Berners-Lee, o criador da web, enquanto ele trabalhava na CERN em 1989 (sua equipe e ele também foram responsáveis pelo HTML).\n",
    "\n",
    "O HTTP possui **duas entidades básicas**: a **Request** (pedido) e a **Response** (resposta)\n",
    "\n",
    "Sempre que entramos em uma página, **enviamos uma request para o servidor** do site e **esperamos uma response** com o HTML da página.\n",
    "\n",
    "Sempre que enviamos uma request devemos especificar um **método**.\n",
    "A tabela abaixo cita os métodos mais comuns e explica brevemente o objetivo de cada um:\n",
    "\n",
    "Método     | Objetivo\n",
    "-----------|-----------\n",
    "**GET**    | Obter informações\n",
    "**POST**   | Salvar informações\n",
    "**PUT**    | Atualizar informações\n",
    "**DELETE** | Deletar informações\n",
    "\n",
    "Todos eles são comumente utilizados por APIs. \n",
    "\n",
    "O método **GET** é o que seu navegador usa para baixar o HTML da página.\n",
    "\n",
    "O metódo **POST** também é muito utilizado sempre que você enviar algum formulário em algum site.\n",
    "\n",
    "---\n",
    "\n",
    "Todos as respostas possuem, além do conteúdo da resposta, um código de status.\n",
    "\n",
    "Os códigos de status (status code) seguem um padrão.\n",
    "\n",
    "Os mais comuns são:\n",
    "\n",
    "Código  |  Significado\n",
    "--------|---------------\n",
    "200     | Ok\n",
    "3XX     | O servidor vai te redirecionar para outra URL\n",
    "4XX     | O recurso não foi encontrado, não está mais disponível, etc\n",
    "5XX     | Algum problema aconteceu no servidor e ele não conseguiu processar a sua request\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como são formadas as APIs REST\n",
    "\n",
    "Podemos dizer que uma API é como se fosse uma página da web só que para apenas sistemas acessarem, lerem e interagirem.\n",
    "\n",
    "Por exemplo, ao acessarmos a API da Jsonplaceholder (https://jsonplaceholder.typicode.com/posts/1), vemos o retorno abaixo, ao invés de uma página comum:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"userId\": 1,\n",
    "  \"id\": 1,\n",
    "  \"title\": \"sunt aut facere repellat provident occaecati excepturi optio reprehenderit\",\n",
    "  \"body\": \"quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\"\n",
    "}\n",
    "```\n",
    "\n",
    "Esse padrão de resposta é o que chamamos de JSON, e este é o tipo de resposta mais comum entre as APIs.\n",
    "\n",
    "Ele foi feito para que máquinas entendam seus dados e os utilizem como quiser.\n",
    "\n",
    "---\n",
    "\n",
    "Outra característica das APIs REST é a divisão dos recursos. Por exemplo:\n",
    "\n",
    "https://jsonplaceholder.typicode.com/users/1\n",
    "\n",
    "Ao abrirmos esta URL estamos fazendo um GET para obtermos informações do usuário (/users) com código 1 (/1).\n",
    "Podemos trocar o código do usuário para buscar outros usuários.\n",
    "\n",
    "Também podemos pedir todos os usuários digitando:\n",
    "\n",
    "https://jsonplaceholder.typicode.com/users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como funciona o pacote Requests\n",
    "\n",
    "Como vimos anteriormente, o pacote requests do Python é utilizado para nos comunicarmos com URLs.\n",
    "\n",
    "Podemos realizar GET, POST, PUT, DELETE e quaisquer outros métodos HTTP com ele.\n",
    "\n",
    "Veja no exemplo abaixo como podemos fazer isso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leanne Graham (Sincere@april.biz) - hildegard.org\n",
      "Ervin Howell (Shanna@melissa.tv) - anastasia.net\n",
      "Clementine Bauch (Nathan@yesenia.net) - ramiro.info\n",
      "Patricia Lebsack (Julianne.OConner@kory.org) - kale.biz\n",
      "Chelsey Dietrich (Lucio_Hettinger@annie.ca) - demarco.info\n",
      "Mrs. Dennis Schulist (Karley_Dach@jasper.info) - ola.org\n",
      "Kurtis Weissnat (Telly.Hoeger@billy.biz) - elvis.io\n",
      "Nicholas Runolfsdottir V (Sherwood@rosamond.me) - jacynthe.com\n",
      "Glenna Reichert (Chaim_McDermott@dana.io) - conrad.com\n",
      "Clementina DuBuque (Rey.Padberg@karina.biz) - ambrose.net\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "api = requests.get('https://jsonplaceholder.typicode.com/users')\n",
    "\n",
    "json = api.json()\n",
    "\n",
    "for user in json:\n",
    "    print('{0} ({1}) - {2}'.format(user['name'], user['email'], user['website']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 2 - Extraindo Dados do CoinMarketCap via API\n",
    "\n",
    "Vamos usar requests para o acessar a API do CoinMarketCap.\n",
    "\n",
    "As instruções da API estão disponíveis em: https://coinmarketcap.com/api/\n",
    "\n",
    "Deveremos extrair os seguintes dados:\n",
    "- Nome da moeda\n",
    "- Preço atual **CONVERTIDO EM REAIS**\n",
    "- O valor de mercado total\n",
    "- O valor atual em circulação\n",
    "- Percentual de mudança nas últimas 24 horas\n",
    "\n",
    "Também deveremos limitar para que a API traga apenas 5 moedas para trabalharmos\n",
    "\n",
    "Tempo: 15 minutos\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "api = requests.get('API')\n",
    "\n",
    "json = api.json()\n",
    "\n",
    "for moeda in json:\n",
    "    nome = 'moed'\n",
    "    preco = '$222'\n",
    "    valor_mercado = '$555' \n",
    "    em_circulacao = '46465'\n",
    "    percentual_dia = '1.56%'\n",
    "    print('{0}: {1} ({2} / 24h)'.format(nome, preco, percentual_dia))\n",
    "    print('Em circulação: {0}'.format(em_circulacao))\n",
    "    print('Valor de mercado: {0}'.format(valor_mercado))\n",
    "    print('-------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escrita e leitura de arquivos em Python\n",
    "\n",
    "\n",
    "Em Python, assim como em outras linguagens de programação, podemos manipular arquivos que estão em nosso disco.\n",
    "\n",
    "Para isso, utilizamos o `open` para nos trazer um objeto de arquivo.\n",
    "\n",
    "O `open` precisa de 1 parâmetro, e suporta mais 2 parametros opcionais.\n",
    "\n",
    "Todo o processo de escrita e leitura de arquivos deve ser feita com muito cuidado. Como são operações mais lentas, você pode acabar travando seu computador se fizer um loop errado enquanto escreve um arquivo.\n",
    "\n",
    "Por isso, é muito importante se lembrar de SEMPRE fechar o arquivo após o uso dele no Python.\n",
    "\n",
    "Vamos ver um exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alô? Alguém me escuta?\n"
     ]
    }
   ],
   "source": [
    "f = open('arquivo_teste.txt', 'r+')\n",
    "\n",
    "f.write('Alô? Alguém me escuta?')\n",
    "\n",
    "print(f.readline())\n",
    "\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
